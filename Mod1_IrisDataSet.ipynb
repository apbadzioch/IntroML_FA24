{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all modules needed\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import IPython\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:12:24) [GCC 11.2.0]\n",
      "pandas version: 2.2.2\n",
      "matplotlib version: 3.8.4\n",
      "NumPy version: 1.26.4\n",
      "SciPy version: 1.13.1\n",
      "IPython version: 8.25.0\n",
      "scikit-learn version: 1.5.1\n"
     ]
    }
   ],
   "source": [
    "# print versions being used\n",
    "print(\"Python version: {}\".format(sys.version))\n",
    "print(\"pandas version: {}\".format(pd.__version__))\n",
    "print(\"matplotlib version: {}\".format(matplotlib.__version__))\n",
    "print(\"NumPy version: {}\".format(np.__version__))\n",
    "print(\"SciPy version: {}\".format(sp.__version__))\n",
    "print(\"IPython version: {}\".format(IPython.__version__))\n",
    "print(\"scikit-learn version: {}\".format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris dataset from scikit_learn\n",
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of iris_dataset: \n",
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "# the iris object loaded is a Bunch object, similar to a dictionary containing Key:Value pairs\n",
    "print(\"Keys of iris_dataset: \\n{}\".format(iris_dataset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 150 (50 in each of three classes)\n",
      ":Number of Attributes: 4 numeric, predictive attributes and the class\n",
      ":Attribute Information:\n",
      "    - sepal length in cm\n",
      "    - sepal width in cm\n",
      "    - petal length in cm\n",
      "    - petal width in cm\n",
      "    - class:\n",
      "            - Iris-Setosa\n",
      "            - Iris-Versicolour\n",
      "            - Iris-Virginica\n",
      "\n",
      "\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# A string that contains detailed text description of the dataset \n",
    "# ['what you want to see'][:slicing to the number of characters]\n",
    "# the elipsis ... means that there is more to read after\n",
    "print(iris_dataset['DESCR'][:440]+\"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target names: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# A NumPy 'array' that contains the names of the target classes\n",
    "print(\"Target names: {}\".format(iris_dataset['target_names']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: \n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# '{}' is the place holder for the .format() method where (datset[list])\n",
    "print(\"Feature names: \\n{}\".format(iris_dataset['feature_names']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five columns of data:\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "# print lines of the dataset .format(dataset['list'][slice:lines])\n",
    "print(\"First five columns of data:\\n{}\".format(iris_dataset['data'][:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing\n",
    "- When assessing a model's performance, the labeled data (input data that has been annotated with the correct output or target value (each data point is paired with a label or category that it belongs to))\n",
    "\n",
    "**The data is broken into two parts, one to build the model**\n",
    "- Training Data (Training Set) is usually about 70% - 80%\n",
    "\n",
    "**The rest is used to assess how well the model works**\n",
    "- Test Data (Test Set) (Hold-out Set) is usually about 20% - 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
